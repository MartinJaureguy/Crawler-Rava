{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Crawler de Rava Online"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea consiste en implementar un scraper de los foros de Rava Online y bajar los datos de la accion GGAL (Grupo Financiero Galicia) utilizando la libreria de BeautifulSoup\n",
    "\n",
    "El mismo esta desarrollado para bajar solamente los ultimos 600 posts a modo de ejemplo. \n",
    "\n",
    "El url inicial es el siguiente: http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=0\n",
    "\n",
    "Mientras que el url final es: http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=15"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final se creara una lista de tamaÃ±o 600 (cantidad de posteos) en donde cada elemento sean los datos bajados de los posts. Cada uno de estos elementos va a ser un diccionario con las claves \"id\" (id del posteo) y \"content\" (texto contenido dentro de cada post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Funciones principales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 1. Obtener codigo html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un url del foro de rava, devuelve el codigo html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gets_html_rava(url):\n",
    "    req = urllib.request.Request(url,\n",
    "                                 headers={'User-Agent':\n",
    "                                          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'})\n",
    "\n",
    "    return(urllib.request.urlopen(req).read().decode(\"utf-8\"))\n",
    "    \n",
    "#html = gets_html_rava(\"http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2. Formato beatiful soup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un codigo html de una pagina de rava, lo transforma en formato beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return soup\n",
    "\n",
    "#soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 3. Obtener ids de una pagina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p5181158', 'p5181157', 'p5181156', 'p5181155', 'p5181154', 'p5181138', 'p5181135', 'p5181120', 'p5181118', 'p5181117', 'p5181115', 'p5181095', 'p5181094', 'p5181093', 'p5181092']\n"
     ]
    }
   ],
   "source": [
    "def process_ids(soup):\n",
    "    ids = []\n",
    "    contenido_con_ids = soup.find_all(\"dl\", {\"class\":\"postprofile\"})\n",
    "    for contenido in contenido_con_ids:\n",
    "        ids_i = contenido.get('id').replace('rofile','')\n",
    "        ids.append(ids_i)\n",
    "        \n",
    "    return ids\n",
    "print(process_ids(soup))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obtener contenido de una pagina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "def process_content(soup):\n",
    "    content = []\n",
    "    contenido_con_content = soup.find_all(\"div\", {\"class\":\"content\"})\n",
    "    for contenido in contenido_con_content:\n",
    "        if bool(contenido.blockquote):\n",
    "            content_i = str(contenido.text).replace(str(contenido.blockquote.text),'')\n",
    "        else:\n",
    "            content_i = str(contenido.text)\n",
    "        content.append(content_i.replace('\\n\\n',\"\"))\n",
    "    \n",
    "    return content\n",
    "print(len(process_content(soup)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Crear diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper():\n",
    "    \n",
    "    base_url = \"http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=\"\n",
    "    \n",
    "    #Genero una lista vacia para ser rellenada con los diccionarios de \"ids\" y \"content\" generados en el scrapping\n",
    "    scraped_data = []\n",
    "    \n",
    "    for i in range(0, 40):  #Se puede modificar el rango para obtener una mayor cantidad de posteos\n",
    "    \n",
    "        url = \"http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=\" + str(15 * i)\n",
    "    \n",
    "        print(url)\n",
    "        \n",
    "        html_data = gets_html_rava(url)\n",
    "        \n",
    "        soup = parse_html(html_data)\n",
    "    \n",
    "        ids = process_ids(soup)\n",
    "        content = process_content(soup)\n",
    "        \n",
    "        #Se genera un diccionario vacio y una lista de indices por cada comentario de la pagina. Por cada comentario, se genera\n",
    "        #un diccionario con el id y el content que luego se agrega a la lista final \"scraped_data\".\n",
    "        post = {}\n",
    "        list_num = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "        for index in list_num:\n",
    "            post[\"id\"] = ids[index]\n",
    "            post[\"content\"] = content[index]\n",
    "            scraped_data.append(post)\n",
    "              \n",
    "    return(scraped_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=0\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=15\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=30\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=45\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=60\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=75\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=90\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=105\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=120\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=135\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=150\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=165\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=180\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=195\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=210\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=225\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=240\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=255\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=270\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=285\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=300\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=315\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=330\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=345\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=360\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=375\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=390\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=405\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=420\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=435\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=450\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=465\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=480\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=495\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=510\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=525\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=540\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=555\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=570\n",
      "http://foro.rava.com/foro3/viewtopic.php?f=1&t=77&start=585\n"
     ]
    }
   ],
   "source": [
    "scraped_data = scraper()\n",
    "\n",
    "with open(\"scraped_data.p\", \"wb\") as f:\n",
    "    pickle.dump(scraped_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'p5181092', 'content': 'Ultimo posteo. Asi no los molesto mas. Leo permanente kirchneristas cabeza de termo fanaticos.\\nYo conozco muchos profesionales kirchneristas, empresarios kirchneristas, etc. Es muy comun que por un tema de represantacion sectorial sean minorias en clases medias altas y altas un sector de centro izquierda.\\nComo tambien es poco comun que sectores de centro derecha o derecha ganen en barrios populares.\\nEsto a mi entender no es por que sean cabeza de termos. Sino por que la mayoria votan.pensando en su propio bienestar. \\nEsto cabe para ambos sectores. \\nUno podria decir que un planero vota para mantener el plan o un empleado de sueldo basico vota un gobierno que supiestamente le va a jugar a fvor en la puja distributiva.\\nComo tambien decir que un propietario de un campo chico o mediano vota una opcion que le prometa bajar retenciones o impuestos.\\nConclusion fanaticos como los llaman hay en todos lados.'}\n",
      "p5181092\n",
      "Ultimo posteo. Asi no los molesto mas. Leo permanente kirchneristas cabeza de termo fanaticos.\n",
      "Yo conozco muchos profesionales kirchneristas, empresarios kirchneristas, etc. Es muy comun que por un tema de represantacion sectorial sean minorias en clases medias altas y altas un sector de centro izquierda.\n",
      "Como tambien es poco comun que sectores de centro derecha o derecha ganen en barrios populares.\n",
      "Esto a mi entender no es por que sean cabeza de termos. Sino por que la mayoria votan.pensando en su propio bienestar. \n",
      "Esto cabe para ambos sectores. \n",
      "Uno podria decir que un planero vota para mantener el plan o un empleado de sueldo basico vota un gobierno que supiestamente le va a jugar a fvor en la puja distributiva.\n",
      "Como tambien decir que un propietario de un campo chico o mediano vota una opcion que le prometa bajar retenciones o impuestos.\n",
      "Conclusion fanaticos como los llaman hay en todos lados.\n"
     ]
    }
   ],
   "source": [
    "with open(\"scraped_data.p\", \"rb\") as f:\n",
    "    scraped_data = pickle.load(f)\n",
    "\n",
    "print(scraped_data[0])\n",
    "print(scraped_data[0][\"id\"])\n",
    "print(scraped_data[0][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
